# Lesson 5: Goroutines and Channels

## Theory

### 1. Goroutines - Lightweight Threads
Goroutines are Go's approach to concurrent programming - much lighter than OS threads.

```go
import (
    "fmt"
    "time"
)

// Basic goroutine
func sayHello(name string) {
    for i := 0; i < 3; i++ {
        fmt.Printf("Hello %s! (%d)\n", name, i)
        time.Sleep(100 * time.Millisecond)
    }
}

func main() {
    // Sequential execution
    sayHello("Alice")
    sayHello("Bob")

    fmt.Println("---")

    // Concurrent execution with goroutines
    go sayHello("Charlie") // Runs in separate goroutine
    go sayHello("Diana")   // Runs in separate goroutine

    // Main goroutine continues immediately
    fmt.Println("Started goroutines")

    // Wait for goroutines to finish (simple approach)
    time.Sleep(500 * time.Millisecond)
    fmt.Println("Done")
}
```

**vs Node.js/TypeScript:**
```typescript
// Node.js async approach
async function sayHello(name: string): Promise<void> {
    for (let i = 0; i < 3; i++) {
        console.log(`Hello ${name}! (${i})`);
        await new Promise(resolve => setTimeout(resolve, 100));
    }
}

async function main() {
    // Sequential
    await sayHello("Alice");
    await sayHello("Bob");

    // Concurrent
    await Promise.all([
        sayHello("Charlie"),
        sayHello("Diana")
    ]);
}
```

### 2. Channels - Communication Between Goroutines
Channels are Go's way of communicating between goroutines. "Don't communicate by sharing memory; share memory by communicating."

```go
// Basic channel usage
func basicChannels() {
    // Create a channel
    ch := make(chan string)

    // Send data in a goroutine
    go func() {
        ch <- "Hello from goroutine!"
    }()

    // Receive data (blocks until data is sent)
    message := <-ch
    fmt.Println(message)
}

// Buffered channels
func bufferedChannels() {
    // Buffered channel (capacity of 3)
    ch := make(chan int, 3)

    // Can send without blocking until buffer is full
    ch <- 1
    ch <- 2
    ch <- 3

    // Read from channel
    fmt.Println(<-ch) // 1
    fmt.Println(<-ch) // 2
    fmt.Println(<-ch) // 3
}

// Channel directions (for function parameters)
func sendOnly(ch chan<- string) {
    ch <- "Can only send"
}

func receiveOnly(ch <-chan string) {
    message := <-ch
    fmt.Println("Received:", message)
}

func bidirectional(ch chan string) {
    ch <- "Can send and receive"
    fmt.Println(<-ch)
}
```

### 3. Select Statement - Multiplexing Channels
Select allows you to wait on multiple channel operations.

```go
func selectExample() {
    ch1 := make(chan string)
    ch2 := make(chan string)

    // Send data after delays
    go func() {
        time.Sleep(100 * time.Millisecond)
        ch1 <- "from ch1"
    }()

    go func() {
        time.Sleep(200 * time.Millisecond)
        ch2 <- "from ch2"
    }()

    // Select waits for the first available channel
    for i := 0; i < 2; i++ {
        select {
        case msg1 := <-ch1:
            fmt.Println("Received", msg1)
        case msg2 := <-ch2:
            fmt.Println("Received", msg2)
        case <-time.After(150 * time.Millisecond):
            fmt.Println("Timeout!")
        }
    }
}

// Non-blocking select with default
func nonBlockingSelect() {
    ch := make(chan string)

    select {
    case msg := <-ch:
        fmt.Println("Received:", msg)
    default:
        fmt.Println("No data available")
    }
}
```

### 4. Worker Pool Pattern
A common pattern for processing many tasks concurrently.

```go
type Job struct {
    ID     int
    Data   string
    Result chan string
}

func worker(id int, jobs <-chan Job, results chan<- string) {
    for job := range jobs {
        fmt.Printf("Worker %d processing job %d\n", id, job.ID)

        // Simulate work
        time.Sleep(time.Duration(rand.Intn(100)) * time.Millisecond)

        result := fmt.Sprintf("Job %d processed by worker %d: %s",
            job.ID, id, strings.ToUpper(job.Data))

        // Send result back
        if job.Result != nil {
            job.Result <- result
        }

        results <- result
    }
}

func workerPoolExample() {
    const numWorkers = 3
    const numJobs = 10

    jobs := make(chan Job, numJobs)
    results := make(chan string, numJobs)

    // Start workers
    for w := 1; w <= numWorkers; w++ {
        go worker(w, jobs, results)
    }

    // Send jobs
    for j := 1; j <= numJobs; j++ {
        jobs <- Job{
            ID:   j,
            Data: fmt.Sprintf("task-%d", j),
        }
    }
    close(jobs)

    // Collect results
    for r := 1; r <= numJobs; r++ {
        result := <-results
        fmt.Println("Result:", result)
    }
}
```

### 5. Context Package - Cancellation and Timeouts
Context is used for cancellation, timeouts, and passing request-scoped values.

```go
import (
    "context"
    "fmt"
    "time"
)

func doWork(ctx context.Context, name string) error {
    for i := 0; i < 5; i++ {
        select {
        case <-ctx.Done():
            return ctx.Err() // Context cancelled or timed out
        default:
            fmt.Printf("%s: working step %d\n", name, i+1)
            time.Sleep(200 * time.Millisecond)
        }
    }
    return nil
}

func contextExamples() {
    // Context with timeout
    fmt.Println("=== With Timeout ===")
    ctx, cancel := context.WithTimeout(context.Background(), 500*time.Millisecond)
    defer cancel()

    err := doWork(ctx, "Task1")
    if err != nil {
        fmt.Printf("Task1 error: %v\n", err)
    }

    // Context with cancellation
    fmt.Println("\n=== With Cancellation ===")
    ctx2, cancel2 := context.WithCancel(context.Background())

    go func() {
        time.Sleep(300 * time.Millisecond)
        fmt.Println("Cancelling task...")
        cancel2()
    }()

    err = doWork(ctx2, "Task2")
    if err != nil {
        fmt.Printf("Task2 error: %v\n", err)
    }

    // Context with deadline
    fmt.Println("\n=== With Deadline ===")
    deadline := time.Now().Add(400 * time.Millisecond)
    ctx3, cancel3 := context.WithDeadline(context.Background(), deadline)
    defer cancel3()

    err = doWork(ctx3, "Task3")
    if err != nil {
        fmt.Printf("Task3 error: %v\n", err)
    }
}
```

### 6. Sync Package - Synchronization Primitives
When you need to synchronize access to shared resources.

```go
import (
    "sync"
    "time"
)

// WaitGroup - wait for multiple goroutines
func waitGroupExample() {
    var wg sync.WaitGroup

    for i := 1; i <= 3; i++ {
        wg.Add(1) // Increment counter

        go func(id int) {
            defer wg.Done() // Decrement when done

            fmt.Printf("Goroutine %d starting\n", id)
            time.Sleep(time.Duration(id*100) * time.Millisecond)
            fmt.Printf("Goroutine %d done\n", id)
        }(i)
    }

    wg.Wait() // Wait for all goroutines to finish
    fmt.Println("All goroutines completed")
}

// Mutex - mutual exclusion
type Counter struct {
    mu    sync.Mutex
    value int
}

func (c *Counter) Increment() {
    c.mu.Lock()
    defer c.mu.Unlock()
    c.value++
}

func (c *Counter) Value() int {
    c.mu.Lock()
    defer c.mu.Unlock()
    return c.value
}

func mutexExample() {
    counter := &Counter{}
    var wg sync.WaitGroup

    // Start 100 goroutines that increment the counter
    for i := 0; i < 100; i++ {
        wg.Add(1)
        go func() {
            defer wg.Done()
            for j := 0; j < 100; j++ {
                counter.Increment()
            }
        }()
    }

    wg.Wait()
    fmt.Printf("Final counter value: %d\n", counter.Value())
}

// RWMutex - reader-writer mutex
type SafeMap struct {
    mu   sync.RWMutex
    data map[string]int
}

func NewSafeMap() *SafeMap {
    return &SafeMap{
        data: make(map[string]int),
    }
}

func (sm *SafeMap) Set(key string, value int) {
    sm.mu.Lock()
    defer sm.mu.Unlock()
    sm.data[key] = value
}

func (sm *SafeMap) Get(key string) (int, bool) {
    sm.mu.RLock()
    defer sm.mu.RUnlock()
    value, exists := sm.data[key]
    return value, exists
}
```

### 7. Pipeline Pattern
Chaining operations through channels.

```go
// Pipeline stages
func generateNumbers(nums ...int) <-chan int {
    out := make(chan int)
    go func() {
        defer close(out)
        for _, n := range nums {
            out <- n
        }
    }()
    return out
}

func squareNumbers(in <-chan int) <-chan int {
    out := make(chan int)
    go func() {
        defer close(out)
        for n := range in {
            out <- n * n
        }
    }()
    return out
}

func filterEven(in <-chan int) <-chan int {
    out := make(chan int)
    go func() {
        defer close(out)
        for n := range in {
            if n%2 == 0 {
                out <- n
            }
        }
    }()
    return out
}

func pipelineExample() {
    // Create pipeline: generate -> square -> filter
    numbers := generateNumbers(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)
    squared := squareNumbers(numbers)
    evens := filterEven(squared)

    // Consume results
    for result := range evens {
        fmt.Printf("Result: %d\n", result)
    }
}
```

### 8. Fan-out/Fan-in Pattern
Distributing work across multiple goroutines and collecting results.

```go
func fanOutFanIn() {
    input := make(chan int)

    // Fan-out: distribute work to multiple workers
    worker1 := processNumbers(input)
    worker2 := processNumbers(input)
    worker3 := processNumbers(input)

    // Fan-in: merge results from workers
    output := merge(worker1, worker2, worker3)

    // Send work
    go func() {
        defer close(input)
        for i := 1; i <= 10; i++ {
            input <- i
        }
    }()

    // Collect results
    for result := range output {
        fmt.Printf("Processed: %d\n", result)
    }
}

func processNumbers(input <-chan int) <-chan int {
    output := make(chan int)
    go func() {
        defer close(output)
        for n := range input {
            // Simulate processing time
            time.Sleep(100 * time.Millisecond)
            output <- n * n
        }
    }()
    return output
}

func merge(channels ...<-chan int) <-chan int {
    output := make(chan int)
    var wg sync.WaitGroup

    // Start a goroutine for each input channel
    for _, ch := range channels {
        wg.Add(1)
        go func(c <-chan int) {
            defer wg.Done()
            for value := range c {
                output <- value
            }
        }(ch)
    }

    // Close output when all inputs are closed
    go func() {
        wg.Wait()
        close(output)
    }()

    return output
}
```

---

## Practice Questions

**Note**: B¡n s½ làm bài t­p trong th° måc `homework/` sau này nhé!

### Basic Level

**1. Concurrent Hello World**
Create a program that starts 5 goroutines, each printing "Hello from goroutine X" 3 times with random delays. Use WaitGroup to ensure all goroutines complete.

**2. Simple Producer-Consumer**
Create a producer that sends numbers 1-10 to a channel, and a consumer that receives and prints them. Add a second consumer that squares the numbers before printing.

### Intermediate Level

**3. URL Fetcher**
Create a concurrent URL fetcher that:
- Takes a list of URLs
- Fetches them concurrently (max 3 concurrent requests)
- Returns results as they complete
- Handles timeouts (5 seconds per request)

**4. File Processor**
Build a file processing pipeline:
- Stage 1: Read filenames from a directory
- Stage 2: Read file contents
- Stage 3: Count words in each file
- Stage 4: Aggregate total word count
Use channels to connect stages.

**5. Rate Limiter**
Implement a rate limiter using channels:
- Allow maximum 5 requests per second
- Queue excess requests
- Provide method to add requests and get results

### Advanced Level

**6. Job Queue System**
Create a distributed job processing system:
```go
type Job interface {
    Process() error
    GetID() string
    GetPriority() int
}

type JobQueue interface {
    AddJob(job Job) error
    Start(numWorkers int) error
    Stop() error
    GetStats() QueueStats
}

type QueueStats struct {
    Processed int
    Failed    int
    Pending   int
}
```

**7. Real-time Chat Server**
Design a chat server using goroutines and channels:
```go
type ChatServer struct {
    clients   map[string]*Client
    broadcast chan *Message
    register  chan *Client
    unregister chan *Client
}

type Client struct {
    ID       string
    Name     string
    Send     chan *Message
    Server   *ChatServer
}

type Message struct {
    From    string
    To      string // empty for broadcast
    Content string
    Type    MessageType
}
```

**8. Microservice Request Router**
Build a request router with load balancing:
```go
type ServiceInstance struct {
    ID       string
    Address  string
    Health   HealthStatus
    Load     int
}

type LoadBalancer interface {
    AddInstance(instance *ServiceInstance) error
    RemoveInstance(id string) error
    Route(request *Request) (*Response, error)
    HealthCheck() error
}

type CircuitBreaker interface {
    Call(fn func() error) error
    GetState() CircuitState
}
```

**9. Event-Driven Microservice**
Create an event-driven system with:
- Event bus with pub/sub pattern
- Event sourcing with replay capability
- Saga pattern for distributed transactions
- Dead letter queue for failed events

**10. Distributed Cache**
Implement a distributed cache system:
```go
type DistributedCache interface {
    Get(key string) (interface{}, error)
    Set(key string, value interface{}, ttl time.Duration) error
    Delete(key string) error
    Subscribe(pattern string) (<-chan CacheEvent, error)
}

type CacheNode struct {
    ID       string
    Address  string
    Data     map[string]*CacheItem
    Peers    []*CacheNode
}
```

Requirements:
- Consistent hashing for key distribution
- Replication across nodes
- Gossi protocol for cluster membership
- Conflict resolution for concurrent updates

---

**Expected Completion Time**: 5-6 hours for thorough understanding and practice

**Next Lesson Preview**: Pointers and Memory Management - Understanding Go's memory model, garbage collection, and performance optimization.